{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b997ed",
   "metadata": {},
   "source": [
    "# Foreign Exchange (FX) Trade Verification and Reconciliation with Data Analysis\n",
    "\n",
    "This notebook is designed to verify FX trade records against bank statements. It aims to identify matched and unmatched transactions for both \"Buy\" and \"Sell\" side operations.\n",
    "\n",
    "**New Features:**\n",
    "- **Data Consistency Emphasis:** Robust parsing and best practices for data integrity.\n",
    "- **Comprehensive Data Analysis:** Summaries and insights into the reconciliation results.\n",
    "- **Beautiful Seaborn Visualizations:** High-quality plots to illustrate key findings.\n",
    "- Export of matched and unmatched records to CSV files.\n",
    "\n",
    "**Instructions:**\n",
    "1. Ensure you have the necessary CSV files (FX Trade Tracker, Bank Statements) ready.\n",
    "2. Upload the files using the provided widgets.\n",
    "3. Run all cells in sequence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8faa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ddf668",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "This section imports all necessary libraries and sets up global configurations. We're adding `matplotlib.pyplot` and `seaborn` for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e3c720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import Output\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style for beautiful plots\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6) # Default figure size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee6d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae52a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Output paths (these will be relative to where the notebook is run or absolute paths)\n",
    "out_csv_path_buy_unmatched = 'UnmatchedCounterpartyPayment.csv'\n",
    "out_csv_path_sell_unmatched = 'UnmatchedChoicePayment.csv'\n",
    "out_csv_path_bank_unmatched = 'UnmatchedBankRecords.csv'\n",
    "out_csv_path_buy_matched = 'MatchedCounterpartyPayment.csv'\n",
    "out_csv_path_sell_matched = 'MatchedChoicePayment.csv'\n",
    "\n",
    "# Date for FX rate (can be dynamically set or user input)\n",
    "# This will be used for any FX conversions\n",
    "fx_rate_date = '2025-07-11' # YYYY-MM-DD for consistency\n",
    "\n",
    "# Various Date Formats to handle different date representations in CSVs\n",
    "date_formats = [\n",
    "    '%Y-%m-%d',\n",
    "    '%Y/%m/%d',\n",
    "    '%d.%m.%Y',\n",
    "    '%Y.%m.%d',\n",
    "    '%d/%m/%Y',\n",
    "    '%-d/%-m/%Y',\n",
    "    '%-d.%-m.%Y'\n",
    "]\n",
    "\n",
    "# Fuzzy matching threshold for bank names (0-100)\n",
    "FUZZY_MATCH_THRESHOLD = 80\n",
    "\n",
    "# Hardcoded FX Rates (for demonstration purposes)\n",
    "# In a real-world scenario, you'd fetch these from an API or a daily data source.\n",
    "# Format: {'CURRENCY_PAIR': RATE} e.g., 'USDKES': 145.0\n",
    "# Assuming all rates are against a base currency (e.g., KES or USD)\n",
    "FX_RATES = {\n",
    "    'USDKES': 145.0,\n",
    "    'EURKES': 155.0,\n",
    "    'GBPUSD': 1.25,\n",
    "    'USDGBP': 0.8, # Inverse rate\n",
    "    'EURUSD': 1.08,\n",
    "    'USDEUR': 0.92, # Inverse rate\n",
    "    'KESUSD': 1/145.0, # Added for completeness\n",
    "    'KESEUR': 1/155.0, # Added for completeness\n",
    "    'USDGBP': 1/1.25, # Added for completeness\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "def get_fx_rate(from_currency, to_currency, date=None):\n",
    "    \"\"\"\n",
    "    Retrieves the FX rate for conversion.\n",
    "    In a real application, this would query a database or an external API.\n",
    "    For this example, it uses the hardcoded FX_RATES.\n",
    "    \"\"\"\n",
    "    from_currency = from_currency.upper()\n",
    "    to_currency = to_currency.upper()\n",
    "\n",
    "    if from_currency == to_currency:\n",
    "        return 1.0\n",
    "\n",
    "    pair = f\"{from_currency}{to_currency}\"\n",
    "    if pair in FX_RATES:\n",
    "        return FX_RATES[pair]\n",
    "\n",
    "    # Try inverse rate\n",
    "    inverse_pair = f\"{to_currency}{from_currency}\"\n",
    "    if inverse_pair in FX_RATES:\n",
    "        return 1 / FX_RATES[inverse_pair]\n",
    "\n",
    "    print(f\"Warning: FX rate not found for {from_currency} to {to_currency}. Assuming 1:1 for demonstration.\")\n",
    "    return 1.0 # Fallback\n",
    "\n",
    "def convert_currency(amount, from_currency, to_currency, date=None):\n",
    "    \"\"\"Converts an amount from one currency to another using the FX_RATES.\"\"\"\n",
    "    print(\"amount : \", amount , \" from currency : \", from_currency, \" to currency : \", to_currency, \" date : \", date)\n",
    "    rate = get_fx_rate(from_currency, to_currency, date)\n",
    "    print(\"rate : \", rate)\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c809ba8",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for Data Consistency and Processing\n",
    "This section defines various utility functions used throughout the reconciliation process, focusing on robust data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3dec08",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def safe_float(x):\n",
    "    \"\"\"Safely converts a value to a float, handling commas, non-numeric inputs, and ensuring consistency.\"\"\"\n",
    "    if pd.isna(x) or x is None:\n",
    "        return None\n",
    "    try:\n",
    "        # Convert to string, remove commas, and strip whitespace\n",
    "        cleaned_x = str(x).replace(',', '').strip()\n",
    "        return float(cleaned_x)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def normalize_bank_key(raw_key):\n",
    "    \"\"\"Normalizes bank names to a consistent short code, using fuzzy matching.\"\"\"\n",
    "    raw_key_lower = str(raw_key).lower().strip()\n",
    "    replacements = {\n",
    "        'ncba bank kenya plc': 'ncba',\n",
    "        'ncba bank': 'ncba',\n",
    "        'equity bank': 'equity',\n",
    "        'i&m bank': 'i&m',\n",
    "        'central bank of kenya': 'cbk',\n",
    "        'kenya commercial bank': 'kcb',\n",
    "        'kcb bank': 'kcb',\n",
    "        'sbm bank (kenya) limited': 'sbm',\n",
    "        'sbm bank': 'sbm',\n",
    "        'absa bank': 'absa',\n",
    "        'kingdom bank': 'kingdom'\n",
    "    }\n",
    "\n",
    "    # First, try direct replacement\n",
    "    for long, short in replacements.items():\n",
    "        if raw_key_lower.startswith(long):\n",
    "            return raw_key_lower.replace(long, short).strip()\n",
    "\n",
    "    # If no direct match, try fuzzy matching against known short codes/replacements\n",
    "    all_bank_names = list(replacements.values()) + list(replacements.keys())\n",
    "    all_bank_names = list(set(all_bank_names)) # Ensure uniqueness\n",
    "\n",
    "    match = process.extractOne(raw_key_lower, all_bank_names, scorer=fuzz.ratio)\n",
    "    if match and match[1] >= FUZZY_MATCH_THRESHOLD:\n",
    "        for long, short in replacements.items():\n",
    "            if match[0].startswith(long):\n",
    "                return short\n",
    "        return match[0]\n",
    "    return raw_key_lower # Return original if no good fuzzy match\n",
    "\n",
    "def resolve_amount_column(columns, action_type, is_sell_side=False):\n",
    "    \"\"\"Identifies the correct amount column (e.g., 'credit', 'debit') based on action type.\"\"\"\n",
    "    columns_lower = [col.lower() for col in columns]\n",
    "    if not is_sell_side: # Refers to the local currency amount in FX trade (Counterparty Payment)\n",
    "        # If it's a 'Bank Buy' from our perspective, we are paying local currency (debit/withdrawal from local acc)\n",
    "        # If it's a 'Bank Sell', we are receiving local currency (credit/deposit to local acc)\n",
    "        if action_type == 'Bank Buy':\n",
    "            return next((columns[i] for i, col in enumerate(columns_lower) if col in ['withdrawal', 'debit']), None)\n",
    "        elif action_type == 'Bank Sell':\n",
    "            return next((columns[i] for i, col in enumerate(columns_lower) if col in ['deposit', 'credit']), None)\n",
    "    else: # is_sell_side refers to the foreign currency amount in FX trade (Choice Payment)\n",
    "        # If it's a 'Bank Buy', we are receiving foreign currency (credit/deposit to foreign acc)\n",
    "        # If it's a 'Bank Sell', we are paying foreign currency (debit/withdrawal from foreign acc)\n",
    "        if action_type == 'Bank Buy':\n",
    "            return next((columns[i] for i, col in enumerate(columns_lower) if col in ['deposit', 'credit']), None)\n",
    "        elif action_type == 'Bank Sell':\n",
    "            return next((columns[i] for i, col in enumerate(columns_lower) if col in ['withdrawal', 'debit']), None)\n",
    "    return None\n",
    "\n",
    "\n",
    "def resolve_date_column(columns):\n",
    "    \"\"\"Identifies the date column from a list of column names, prioritizing common formats.\"\"\"\n",
    "    for candidate in ['Value Date', 'Transaction Date', 'MyUnknownColumn', 'Transaction date', 'Date', 'Activity Date']:\n",
    "        if candidate in columns:\n",
    "            return candidate\n",
    "    return None\n",
    "\n",
    "def get_amount_columns(columns):\n",
    "    \"\"\"Returns a list of potential amount columns.\"\"\"\n",
    "    return [col for col in columns if col.lower() in ['deposit', 'credit', 'withdrawal', 'debit', 'amount', 'value']]\n",
    "\n",
    "def get_description_columns(columns):\n",
    "    \"\"\"Identifies the description column from a list of column names.\"\"\"\n",
    "    for desc in ['Transaction details','Transaction', 'Customer reference','Narration',\n",
    "                 'Transaction Details', 'Detail',  'Transaction Remarks:',\n",
    "                 'TransactionDetails', 'Description', 'Narrative', 'Remarks']:\n",
    "        if desc in columns:\n",
    "            return desc\n",
    "    return None\n",
    "\n",
    "def parse_date(date_str_raw):\n",
    "    \"\"\"Parses a date string into a datetime object using predefined formats.\"\"\"\n",
    "    if not isinstance(date_str_raw, str):\n",
    "        return None\n",
    "    # Attempt to parse as date only, stripping time if present\n",
    "    date_str = date_str_raw.split()[0].strip()\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02197bb8",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "Use the file upload widgets below to load your FX Trade Tracker and Bank Statement CSV files.\n",
    "The robust checks ensure that the data is loaded correctly and handles cases where files are not yet uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9162f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 FX Upload with Sheet Selector + Column Mapping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3e2c3a1bc6458c934a4f3b4c049d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value=(), accept='.csv,.xlsx', description='Upload FX Tracker'), Button(button_style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa49b6e89e47478ebf6810d706061395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='No FX file uploaded.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eef0594877148a5ad68cd6ca7cf84d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Sheet:', layout=Layout(width='300px'), options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e251e5780fa14118a08e07e5f6ed991a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Columns:', layout=Layout(width='300px'), options=(), value=())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c52e6701c44fb6806a3604327a75a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdbab3581544c00b40ffab4fe30fbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fx_upload_widget = widgets.FileUpload(\n",
    "    accept='.csv,.xlsx',\n",
    "    multiple=False,\n",
    "    description='Upload FX Tracker'\n",
    ")\n",
    "fx_output = Output()\n",
    "fx_sheet_dropdown = widgets.Dropdown(description='Sheet:', layout=widgets.Layout(width='300px'), visible=False)\n",
    "fx_column_selector = widgets.SelectMultiple(description='Columns:', layout=widgets.Layout(width='300px'))\n",
    "fx_column_renames = {}\n",
    "fx_column_rename_box = widgets.VBox()\n",
    "fx_file_label = widgets.Label(value=\"No FX file uploaded.\")\n",
    "process_fx_btn = widgets.Button(description='Process FX Data', button_style='success')\n",
    "clear_fx_btn = widgets.Button(description='Clear FX Upload', button_style='danger')\n",
    "fx_controls = widgets.HBox([fx_upload_widget, clear_fx_btn, process_fx_btn])\n",
    "\n",
    "fx_raw_file = None\n",
    "fx_trade_df = pd.DataFrame()\n",
    "fx_sheet_names = []\n",
    "\n",
    "# ========== HELPERS ==========\n",
    "\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "def generate_download_link(df, filename):\n",
    "    csv_data = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv_data.encode()).decode()\n",
    "    return widgets.HTML(value=f'<a download=\"{filename}\" href=\"data:text/csv;base64,{b64}\" target=\"_blank\">Download {filename}</a>')\n",
    "\n",
    "def extract_excel_sheets(file_dict):\n",
    "    excel_file = pd.ExcelFile(io.BytesIO(file_dict['content']))\n",
    "    return excel_file.sheet_names\n",
    "\n",
    "def build_column_rename_fields(columns):\n",
    "    fields = []\n",
    "    fx_column_renames.clear()\n",
    "    for col in columns:\n",
    "        input_widget = widgets.Text(value=col, description=col, layout=widgets.Layout(width='400px'))\n",
    "        fx_column_renames[col] = input_widget\n",
    "        fields.append(input_widget)\n",
    "    fx_column_rename_box.children = fields\n",
    "\n",
    "# ========== CALLBACKS ==========\n",
    "\n",
    "@fx_output.capture()\n",
    "def load_fx_file(change):\n",
    "    global fx_raw_file, fx_sheet_names\n",
    "    fx_output.clear_output()\n",
    "    fx_column_selector.options = []\n",
    "    fx_column_rename_box.children = []\n",
    "    fx_sheet_dropdown.options = []\n",
    "    fx_sheet_dropdown.visible = False\n",
    "    fx_raw_file = None\n",
    "    files = fx_upload_widget.value\n",
    "\n",
    "    if not files:\n",
    "        fx_file_label.value = \"No FX file uploaded.\"\n",
    "        return\n",
    "\n",
    "    file = files[0]\n",
    "    fx_file_label.value = f\"Uploaded: {file['name']}\"\n",
    "    fx_raw_file = file\n",
    "\n",
    "    if file['name'].endswith('.xlsx'):\n",
    "        fx_sheet_names = extract_excel_sheets(file)\n",
    "        fx_sheet_dropdown.options = fx_sheet_names\n",
    "        fx_sheet_dropdown.value = fx_sheet_names[0]\n",
    "        fx_sheet_dropdown.visible = True\n",
    "        display(widgets.HTML(\"<b>Select sheet before processing</b>\"))\n",
    "    else:\n",
    "        # CSV case – preview immediately\n",
    "        df = pd.read_csv(io.BytesIO(file['content']))\n",
    "        fx_column_selector.options = list(df.columns)\n",
    "        build_column_rename_fields(df.columns)\n",
    "        display(df.head())\n",
    "\n",
    "def process_fx_data(change):\n",
    "    global fx_trade_df\n",
    "    fx_output.clear_output()\n",
    "    if not fx_raw_file:\n",
    "        print(\"⚠️ No FX file loaded.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if fx_raw_file['name'].endswith('.xlsx'):\n",
    "            df = pd.read_excel(io.BytesIO(fx_raw_file['content']), sheet_name=fx_sheet_dropdown.value)\n",
    "        else:\n",
    "            df = pd.read_csv(io.BytesIO(fx_raw_file['content']))\n",
    "        \n",
    "        df.columns = df.columns.str.strip()\n",
    "        selected_cols = list(fx_column_selector.value)\n",
    "        if selected_cols:\n",
    "            df = df[selected_cols]\n",
    "\n",
    "        renamed_cols = {col: w.value for col, w in fx_column_renames.items() if col in df.columns and w.value}\n",
    "        df.rename(columns=renamed_cols, inplace=True)\n",
    "\n",
    "        fx_trade_df = df\n",
    "\n",
    "        print(\"✅ FX Data Processed:\")\n",
    "        display(fx_trade_df.head())\n",
    "        display(generate_download_link(fx_trade_df, \"processed_fx_data.csv\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing FX file: {e}\")\n",
    "\n",
    "def clear_fx_data(change):\n",
    "    global fx_raw_file, fx_trade_df\n",
    "    fx_upload_widget.value = ()\n",
    "    fx_file_label.value = \"No FX file uploaded.\"\n",
    "    fx_column_selector.options = []\n",
    "    fx_column_rename_box.children = []\n",
    "    fx_output.clear_output()\n",
    "    fx_raw_file = None\n",
    "    fx_trade_df = pd.DataFrame()\n",
    "\n",
    "# ========== EVENTS ==========\n",
    "\n",
    "fx_upload_widget.observe(load_fx_file, names='value')\n",
    "clear_fx_btn.on_click(clear_fx_data)\n",
    "process_fx_btn.on_click(process_fx_data)\n",
    "fx_column_selector.observe(lambda change: build_column_rename_fields(change['new']), names='value')\n",
    "# Handle sheet selection (only needed for Excel)\n",
    "def handle_sheet_selection(change):\n",
    "    if not fx_raw_file or not fx_raw_file['name'].endswith('.xlsx'):\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_excel(io.BytesIO(fx_raw_file['content']), sheet_name=change['new'])\n",
    "        df.columns = df.columns.str.strip()\n",
    "        fx_column_selector.options = list(df.columns)\n",
    "        build_column_rename_fields(df.columns)\n",
    "        display(df.head())\n",
    "    except Exception as e:\n",
    "        fx_output.clear_output()\n",
    "        print(f\"❌ Failed to load sheet: {e}\")\n",
    "\n",
    "fx_sheet_dropdown.observe(handle_sheet_selection, names='value')\n",
    "\n",
    "# ========== DISPLAY UI ==========\n",
    "\n",
    "print(\"📥 FX Upload with Sheet Selector + Column Mapping\")\n",
    "display(fx_controls, fx_file_label, fx_sheet_dropdown, fx_column_selector, fx_column_rename_box, fx_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏦 Enhanced Bank Upload Interface:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd68067fe194092b3a563ca24e63b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value=(), accept='.csv,.xlsx', description='Upload Bank Statement(s)', multiple=True…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62bf5972afa4a7c9b760f778f289d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='No bank files uploaded.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8130a66395fe4d95b1cfe0baab28fb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681d48e7370445e4a2b2a9bd90ca8cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efe383d986342d4911fd78aca42a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# === Imports ===\n",
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# %%\n",
    "# === Globals ===\n",
    "bank_raw_files = []\n",
    "bank_dfs = {}\n",
    "\n",
    "# File table widget\n",
    "uploaded_file_table = widgets.VBox()\n",
    "\n",
    "# %%\n",
    "# === Helpers ===\n",
    "def normalize_bank_key(name):\n",
    "    return name.strip().lower().replace(' ', '_').replace('.csv', '').replace('.xlsx', '')\n",
    "\n",
    "def generate_download_link(df, filename):\n",
    "    csv_data = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv_data.encode()).decode()\n",
    "    return widgets.HTML(value=f'<a download=\"{filename}\" href=\"data:text/csv;base64,{b64}\" target=\"_blank\">Download {filename}</a>')\n",
    "\n",
    "def extract_excel_sheets(file_dict):\n",
    "    excel_file = pd.ExcelFile(io.BytesIO(file_dict['content']))\n",
    "    return excel_file.sheet_names\n",
    "\n",
    "def build_bank_file_ui(file_dict):\n",
    "    name = file_dict['name']\n",
    "    content = file_dict['content']\n",
    "    file_size_kb = len(content) / 1024\n",
    "    file_box = widgets.VBox()\n",
    "    file_label = widgets.HTML(f\"<b>🧾 {name}</b> <span style='color:gray'>({file_size_kb:.1f} KB)</span>\")\n",
    "    \n",
    "    dropdown = widgets.Dropdown(description=\"Sheet:\", visible=False, layout=widgets.Layout(width=\"300px\"))\n",
    "    column_selector = widgets.SelectMultiple(description=\"Columns:\", layout=widgets.Layout(width=\"300px\"))\n",
    "    rename_fields_box = widgets.VBox()\n",
    "    rename_fields = {}\n",
    "\n",
    "    preview_output = widgets.Output(layout={'border': '1px solid lightgray', 'padding': '5px'})\n",
    "    df = None\n",
    "\n",
    "    if name.endswith('.xlsx'):\n",
    "        try:\n",
    "            sheet_names = extract_excel_sheets(file_dict)\n",
    "            dropdown.options = sheet_names\n",
    "            dropdown.value = sheet_names[0]\n",
    "            dropdown.visible = True\n",
    "        except Exception as e:\n",
    "            file_label.value += f\" ❌ <span style='color:red'>Error reading Excel sheets: {e}</span>\"\n",
    "\n",
    "    def try_read_csv(bytes_obj):\n",
    "        encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
    "        for enc in encodings:\n",
    "            try:\n",
    "                return pd.read_csv(io.BytesIO(bytes_obj), encoding=enc)\n",
    "            except Exception:\n",
    "                continue\n",
    "        raise ValueError(\"Failed to decode CSV using common encodings.\")\n",
    "\n",
    "    try:\n",
    "        if name.endswith('.xlsx'):\n",
    "            df = pd.read_excel(io.BytesIO(content), sheet_name=dropdown.value)\n",
    "        else:\n",
    "            df = try_read_csv(content)\n",
    "\n",
    "        df.columns = df.columns.str.strip()\n",
    "        column_selector.options = list(df.columns)\n",
    "\n",
    "        for col in df.columns:\n",
    "            input_widget = widgets.Text(value=col, description=col, layout=widgets.Layout(width='400px'))\n",
    "            rename_fields[col] = input_widget\n",
    "        rename_fields_box.children = list(rename_fields.values())\n",
    "\n",
    "        with preview_output:\n",
    "            print(\"📊 Preview:\")\n",
    "            display(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        file_label.value += f\" ❌ <span style='color:red'>Error reading file: {e}</span>\"\n",
    "\n",
    "    bank_raw_files.append({\n",
    "        'file_dict': file_dict,\n",
    "        'dropdown': dropdown,\n",
    "        'column_selector': column_selector,\n",
    "        'rename_fields': rename_fields_box,\n",
    "        'rename_map': rename_fields,\n",
    "        'df_preview': df,\n",
    "        'key': normalize_bank_key(name)\n",
    "    })\n",
    "\n",
    "    file_box.children = [file_label, dropdown, column_selector, rename_fields_box, preview_output]\n",
    "    return file_box\n",
    "\n",
    "# %%\n",
    "# Widgets\n",
    "bank_upload_widget = widgets.FileUpload(accept='.csv,.xlsx', multiple=True, description='Upload Bank Statement(s)')\n",
    "clear_bank_btn = widgets.Button(description='Clear Bank Uploads', button_style='danger')\n",
    "process_bank_btn = widgets.Button(description='Process Bank Data', button_style='success')\n",
    "bank_file_label = widgets.Label(value=\"No bank files uploaded.\")\n",
    "bank_output = widgets.Output()\n",
    "bank_file_boxes = widgets.VBox()\n",
    "\n",
    "# Controls group\n",
    "bank_controls = widgets.HBox([bank_upload_widget, clear_bank_btn, process_bank_btn])\n",
    "\n",
    "# %%\n",
    "def load_bank_files(change):\n",
    "    bank_output.clear_output()\n",
    "    bank_file_boxes.children = []\n",
    "    bank_raw_files.clear()\n",
    "\n",
    "    files = bank_upload_widget.value\n",
    "\n",
    "    # Normalize file input\n",
    "    normalized_files = []\n",
    "    if isinstance(files, dict):  # Classic Notebook\n",
    "        for name, meta in files.items():\n",
    "            normalized_files.append({\n",
    "                'name': name,\n",
    "                'content': meta['content']\n",
    "            })\n",
    "    elif isinstance(files, (list, tuple)):  # JupyterLab/Colab\n",
    "        for file_obj in files:\n",
    "            normalized_files.append({\n",
    "                'name': file_obj['name'],\n",
    "                'content': file_obj['content']\n",
    "            })\n",
    "\n",
    "    if normalized_files:\n",
    "        uploaded_file_table.children = []  # Reset table\n",
    "        header_row = widgets.HBox([\n",
    "            widgets.HTML(\"<b>File</b>\", layout=widgets.Layout(width=\"40%\")),\n",
    "            widgets.HTML(\"<b>Size (KB)</b>\", layout=widgets.Layout(width=\"15%\")),\n",
    "            widgets.HTML(\"<b>Type</b>\", layout=widgets.Layout(width=\"15%\")),\n",
    "            widgets.HTML(\"<b>Action</b>\", layout=widgets.Layout(width=\"20%\"))\n",
    "        ])\n",
    "        table_rows = [header_row]\n",
    "        names = []\n",
    "\n",
    "        for file_dict in normalized_files:\n",
    "            box = build_bank_file_ui(file_dict)\n",
    "            bank_file_boxes.children += (box,)\n",
    "            name = file_dict['name']\n",
    "            content = file_dict['content']\n",
    "            size_kb = len(content) / 1024\n",
    "            file_ext = name.split('.')[-1].lower()\n",
    "            file_icon = \"📊\" if file_ext == \"xlsx\" else \"📄\"\n",
    "            file_type = \"Excel\" if file_ext == \"xlsx\" else \"CSV\"\n",
    "            names.append(name)\n",
    "\n",
    "            remove_btn = widgets.Button(\n",
    "                description=\"Remove\",\n",
    "                button_style=\"danger\",\n",
    "                layout=widgets.Layout(width=\"90px\", height=\"30px\")\n",
    "            )\n",
    "\n",
    "            def make_remove_callback(name_to_remove):\n",
    "                def _remove(_):\n",
    "                    bank_file_boxes.children = tuple(\n",
    "                        box for box in bank_file_boxes.children\n",
    "                        if not any(name_to_remove in str(child) for child in box.children)\n",
    "                    )\n",
    "                    bank_raw_files[:] = [\n",
    "                        entry for entry in bank_raw_files if entry['file_dict']['name'] != name_to_remove\n",
    "                    ]\n",
    "                    uploaded_file_table.children = tuple(\n",
    "                        row for row in uploaded_file_table.children\n",
    "                        if name_to_remove not in str(row.children[0].value)\n",
    "                    )\n",
    "                    if not bank_raw_files:\n",
    "                        bank_file_label.value = \"No bank files uploaded.\"\n",
    "                        uploaded_file_table.children = [header_row]\n",
    "                return _remove\n",
    "\n",
    "            remove_btn.on_click(make_remove_callback(name))\n",
    "\n",
    "            row = widgets.HBox([\n",
    "                widgets.HTML(f\"{file_icon} {name}\", layout=widgets.Layout(width=\"40%\")),\n",
    "                widgets.HTML(f\"{size_kb:.1f}\", layout=widgets.Layout(width=\"15%\")),\n",
    "                widgets.HTML(file_type, layout=widgets.Layout(width=\"15%\")),\n",
    "                remove_btn\n",
    "            ])\n",
    "            table_rows.append(row)\n",
    "\n",
    "        uploaded_file_table.children = table_rows\n",
    "        bank_file_label.value = f\"Uploaded: {', '.join(names)}\"\n",
    "    else:\n",
    "        bank_file_label.value = \"No bank files uploaded.\"\n",
    "        uploaded_file_table.children = []\n",
    "\n",
    "# %%\n",
    "def clear_bank_files(change):\n",
    "    global bank_raw_files, bank_dfs\n",
    "    bank_upload_widget.value = ()\n",
    "    bank_upload_widget._counter = 0\n",
    "    bank_raw_files.clear()\n",
    "    bank_dfs.clear()\n",
    "    bank_file_label.value = \"No bank files uploaded.\"\n",
    "    uploaded_file_table.children = []\n",
    "    bank_file_boxes.children = []\n",
    "    bank_output.clear_output()\n",
    "\n",
    "# %%\n",
    "def process_bank_files(change):\n",
    "    global bank_dfs\n",
    "    bank_output.clear_output()\n",
    "    if not bank_raw_files:\n",
    "        with bank_output:\n",
    "            print(\"⚠️ No bank files to process.\")\n",
    "            return\n",
    "\n",
    "    for entry in bank_raw_files:\n",
    "        file = entry['file_dict']\n",
    "        sheet = entry['dropdown'].value if file['name'].endswith('.xlsx') else None\n",
    "        selected_cols = list(entry['column_selector'].value)\n",
    "        rename_map = {col: widget.value for col, widget in entry['rename_map'].items() if widget.value}\n",
    "\n",
    "        try:\n",
    "            if file['name'].endswith('.xlsx'):\n",
    "                df = pd.read_excel(io.BytesIO(file['content']), sheet_name=sheet)\n",
    "            else:\n",
    "                df = pd.read_csv(io.BytesIO(file['content']))\n",
    "\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if selected_cols:\n",
    "                df = df[selected_cols]\n",
    "            df.rename(columns=rename_map, inplace=True)\n",
    "            key = entry['key']\n",
    "            bank_dfs[key] = df\n",
    "\n",
    "            with bank_output:\n",
    "                print(f\"✅ Processed {file['name']}:\")\n",
    "                display(df.head())\n",
    "                display(generate_download_link(df, f\"{key}_processed.csv\"))\n",
    "        except Exception as e:\n",
    "            with bank_output:\n",
    "                print(f\"❌ Error processing {file['name']}: {e}\")\n",
    "\n",
    "# %%\n",
    "# Register event handlers\n",
    "bank_upload_widget.observe(load_bank_files, names='value')\n",
    "clear_bank_btn.on_click(clear_bank_files)\n",
    "process_bank_btn.on_click(process_bank_files)\n",
    "\n",
    "# %%\n",
    "# Display UI\n",
    "print(\"🏦 Enhanced Bank Upload Interface:\")\n",
    "display(bank_controls, bank_file_label, uploaded_file_table, bank_file_boxes, bank_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ff5fd",
   "metadata": {},
   "source": [
    "## 4. Core Matching Logic\n",
    "This section contains the main function to process FX trade records and attempt to match them against bank statements.\n",
    "This logic ensures consistent comparison between trade records and bank entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff67a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_tolerance_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=0,\n",
    "    max=7,\n",
    "    step=1,\n",
    "    description='Date Tolerance (± days):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "display(date_tolerance_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78966759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d239f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_fx_match(\n",
    "    fx_row: pd.Series,\n",
    "    all_bank_dfs: dict,\n",
    "    unmatched_list: list,\n",
    "    matched_list: list,\n",
    "    action_type: str,\n",
    "    fx_amount_field: str,\n",
    "    bank_currency_info_field: str,\n",
    "    is_sell_side: bool,\n",
    "    date_tolerance_days: int = 3  # <-- default if not passed\n",
    "\n",
    ") -> bool:\n",
    "    print(f\"\\n🔍 Processing FX row: {fx_row.to_dict()}\")\n",
    "\n",
    "    amount = safe_float(fx_row.get(fx_amount_field))\n",
    "    if amount is None or action_type not in ['Bank Buy', 'Bank Sell']:\n",
    "        print(\"❌ Skipping row due to invalid amount or action type\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    parsed_date = fx_row.get('Created At')\n",
    "    if parsed_date:\n",
    "        parsed_date = pd.to_datetime(parsed_date)\n",
    "\n",
    "    if not isinstance(parsed_date, datetime):\n",
    "        print(\"❌ Skipping row due to invalid or missing date\")\n",
    "        return False\n",
    "\n",
    "    formatted_date_slash = parsed_date.strftime('%d/%m/%Y')\n",
    "    formatted_date_dot = parsed_date.strftime('%d.%m.%Y')\n",
    "\n",
    "    print(f\"Bank currency info field : {bank_currency_info_field}\")\n",
    "\n",
    "    counterparty_raw = str(fx_row.get(bank_currency_info_field, '')).strip()\n",
    "    parts = counterparty_raw.split('-')\n",
    "    if len(parts) < 2:\n",
    "        print(f\"❌ Invalid bank-currency format: {counterparty_raw}\")\n",
    "        return False\n",
    "\n",
    "    trade_bank_name = parts[0].strip()\n",
    "    trade_currency = parts[1].strip().upper()\n",
    "\n",
    "    normalized_trade_bank_key_prefix = normalize_bank_key(trade_bank_name)\n",
    "    trade_bank_key_full = f\"{normalized_trade_bank_key_prefix} {trade_currency}\".lower()\n",
    "\n",
    "    print(f\"🔍 Matching against bank key: {trade_bank_key_full}\")\n",
    "\n",
    "    found_match = False\n",
    "    target_bank_df_key = None\n",
    "\n",
    "\n",
    "    for bank_df_key_in_dict in all_bank_dfs.keys():\n",
    "        print(f\"👉 Checking bank key: {bank_df_key_in_dict}\", \" BANK DICT : \", trade_bank_key_full, trade_bank_key_full.startswith(bank_df_key_in_dict.split(' ')[0]))\n",
    "              \n",
    "        if (trade_bank_key_full.startswith(bank_df_key_in_dict.split('_')[0]) and\n",
    "            trade_currency == bank_df_key_in_dict.split('_')[1].upper()):\n",
    "            target_bank_df_key = bank_df_key_in_dict\n",
    "            print(f\"✅ Exact prefix match found with {target_bank_df_key}\")\n",
    "            break\n",
    "        elif fuzz.ratio(trade_bank_key_full, bank_df_key_in_dict) >= FUZZY_MATCH_THRESHOLD:\n",
    "            target_bank_df_key = bank_df_key_in_dict\n",
    "            print(f\"✅ Fuzzy match found with {target_bank_df_key}\")\n",
    "            break\n",
    "\n",
    "    if not target_bank_df_key:\n",
    "        print(\"❌ No matching bank statement found\")\n",
    "        unmatched_list.append({\n",
    "            'Date': parsed_date.strftime('%Y-%m-%d'),\n",
    "            'Bank Table (Expected)': trade_bank_key_full,\n",
    "            'Action Type': action_type,\n",
    "            'Amount': amount,\n",
    "            'Status': 'No Bank Statement Found',\n",
    "            'Source Column': bank_currency_info_field\n",
    "        })\n",
    "        return False\n",
    "\n",
    "    bank_df = all_bank_dfs[target_bank_df_key]\n",
    "    bank_df_columns = bank_df.columns.tolist()\n",
    " \n",
    "    date_column = resolve_date_column(bank_df_columns)\n",
    "    amount_column = resolve_amount_column(bank_df_columns, action_type, is_sell_side)\n",
    "\n",
    "    print(f\"📅 Using date column: {date_column} | 💰 Using amount column: {amount_column}\")\n",
    "\n",
    "    if not date_column or not amount_column:\n",
    "        print(\"❌ Missing date or amount column in bank data\")\n",
    "        unmatched_list.append({\n",
    "            'Date': parsed_date.strftime('%Y-%m-%d'),\n",
    "            'Bank Table (Expected)': target_bank_df_key,\n",
    "            'Action Type': action_type,\n",
    "            'Amount': amount,\n",
    "            'Status': 'Missing Date/Amount Column in Bank Statement',\n",
    "            'Source Column': bank_currency_info_field\n",
    "        })\n",
    "        return False\n",
    "\n",
    "       \n",
    "    p_date = pd.to_datetime(parsed_date.strftime('%Y-%d-%m'))\n",
    "    bank_df['_ParsedDate'] = bank_df[date_column].apply(parse_date)\n",
    "  \n",
    "    valid_dates_df = bank_df[bank_df['_ParsedDate'].notna()]\n",
    "    date_matches = valid_dates_df[\n",
    "        valid_dates_df['_ParsedDate'].dt.date.between(\n",
    "            p_date.date() - pd.Timedelta(days=date_tolerance_days),\n",
    "            p_date.date() + pd.Timedelta(days=date_tolerance_days)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "    print(f\"🔎 Found {len(date_matches)} date matches in bank statement\")\n",
    "\n",
    "    bank_statement_currency = target_bank_df_key.split(' ')[-1].upper()\n",
    "\n",
    "    for idx, bank_row in date_matches.iterrows():\n",
    "        bank_amt_raw = bank_row.get(amount_column)\n",
    "        bank_amt = safe_float(bank_amt_raw)\n",
    "\n",
    "        print(\"\\nbank amount raw : \", bank_amt_raw, \" : converted amount : \", bank_amt ,\"\\n \" )\n",
    "\n",
    "        if bank_amt is not None:\n",
    "            converted_amount = convert_currency(amount, trade_currency, bank_statement_currency, parsed_date)\n",
    "            print(f\"🔄 Comparing bank {bank_amt} to FX {converted_amount} (converted)\")\n",
    "\n",
    "            if converted_amount is not None and abs(converted_amount) > 1.0:\n",
    "                print(\"✅ Match found!\")\n",
    "                matched_list.append({\n",
    "                    'Date': parsed_date.strftime('%Y-%m-%d'),\n",
    "                    'Bank Table': target_bank_df_key,\n",
    "                    'Action Type': action_type,\n",
    "                    'Trade Amount': amount,\n",
    "                    'Trade Currency': trade_currency,\n",
    "                    'Bank Statement Amount': bank_amt,\n",
    "                    'Bank Statement Currency': bank_statement_currency,\n",
    "                    'Converted Trade Amount': converted_amount,\n",
    "                    'Matched In Column': amount_column,\n",
    "                    'Date Column Used': date_column,\n",
    "                    'Source Column': bank_currency_info_field\n",
    "                })\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "    if not found_match:\n",
    "        print(\"❌ No match found in statement rows\")\n",
    "        unmatched_list.append({\n",
    "            'Date': parsed_date.strftime('%Y-%m-%d'),\n",
    "            'Bank Table (Expected)': target_bank_df_key,\n",
    "            'Action Type': action_type,\n",
    "            'Amount': amount,\n",
    "            'Status': 'Not Found in Bank Statement (Amount or No Match)',\n",
    "            'Source Column': bank_currency_info_field\n",
    "        })\n",
    "\n",
    "    return found_match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558c1c1",
   "metadata": {},
   "source": [
    "## 5. Execution and Processing\n",
    "This section orchestrates the matching process using the loaded data. It will generate lists of matched and unmatched transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224eb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_match_count = 0\n",
    "sell_match_count = 0\n",
    "unmatched_buy = []\n",
    "unmatched_sell = []\n",
    "unmatched_bank_records = []\n",
    "matched_buy = []\n",
    "matched_sell = []\n",
    "matched_set = set() # To track matched bank records to avoid double counting for bank-only unmatched\n",
    "\n",
    "if not fx_trade_df.empty and bank_dfs:\n",
    "    print(\"\\n--- Starting Reconciliation Process ---\")\n",
    "\n",
    "\n",
    "    # Ensure column names are stripped of whitespace for consistent access\n",
    "    fx_trade_df.columns = fx_trade_df.columns.str.strip()\n",
    "\n",
    "    # Process each row in the FX trade tracker\n",
    "    for index, row in fx_trade_df.iterrows():\n",
    "        action_type = str(row.get('Action Type', '')).strip()\n",
    "        status = str(row.get('Status', '')).strip().lower()\n",
    "\n",
    "        if status == 'cancelled':\n",
    "            continue\n",
    "\n",
    "        # Process Buy Side (Counterparty Payment)\n",
    "        # Note: 'MyUnknownColumn' is assumed to contain 'Bank-Currency' for the buy-side transaction.\n",
    "        # This means we are buying foreign currency, which implies a local currency payment OUT (debit)\n",
    "        if process_fx_match(\n",
    "            row,\n",
    "            bank_dfs,\n",
    "            unmatched_buy,\n",
    "            matched_buy,\n",
    "            action_type,\n",
    "            'Buy Currency Amount', # This is the local currency amount in the FX trade\n",
    "            'Buy Trade Info', # This column holds \"Bank-Currency\" for the local currency account\n",
    "            False, # Not a sell-side currency for bank account impact perspective\n",
    "            date_tolerance_days=date_tolerance_slider.value  # 👈 Get live slider value\n",
    "\n",
    "        ):\n",
    "            buy_match_count += 1\n",
    "            bank_info = row.get('Buy Trade Info')\n",
    "            buy_amount_fx = safe_float(row.get('Buy Currency Amount'))\n",
    "            p_createdAt = parse_date(row.get('Created At'))\n",
    "            print(\"bank info\", bank_info, \" : buy amount : \", buy_amount_fx)\n",
    "            if bank_info and buy_amount_fx is not None and isinstance(p_createdAt, datetime):\n",
    "                parts = bank_info.lower().split('-')\n",
    "                print(\"bank info : \", bank_info)\n",
    "                if len(parts) >= 2:\n",
    "                    key_bank = normalize_bank_key(parts[0].strip())\n",
    "                    key_currency = parts[1].strip().upper()\n",
    "                    # Add to matched_set with the amount in the bank statement's currency\n",
    "                    # We need the converted amount here. For simplicity, if we match, we assume\n",
    "                    # the bank amount was the one that truly matched.\n",
    "                    # Or, even better, use the amount as it appears in the matched_buy list for consistency\n",
    "                    matched_entry = next((item for item in matched_buy if item['Date'] == p_createdAt.strftime('%Y-%m-%d') and item['Trade Amount'] == buy_amount_fx), None)\n",
    "                    if matched_entry:\n",
    "                         matched_set.add((f\"{key_bank.replace(\"_bank\", \"\")} {key_currency}\", buy_amount_fx, matched_entry['Date']))\n",
    "\n",
    "\n",
    "        # Process Sell Side (Choice Payment)\n",
    "        # Note: 'MyUnknownColumn_[2]' is assumed to contain 'Bank-Currency' for the sell-side transaction.\n",
    "        # This means we are selling foreign currency, which implies a foreign currency payment OUT (debit)\n",
    "        sell_amount_fx = safe_float(row.get('Sell Currency Amount'))\n",
    "        if process_fx_match(\n",
    "            row,\n",
    "            bank_dfs,\n",
    "            unmatched_sell,\n",
    "            matched_sell,\n",
    "            action_type,\n",
    "            'Sell Currency Amount', # This is the foreign currency amount in the FX trade\n",
    "            'Sell Trade Info', # This column holds \"Bank-Currency\" for the foreign currency account\n",
    "            True # This is a sell-side currency for bank account impact perspective\n",
    "        ):\n",
    "            sell_match_count += 1\n",
    "            bank_info = row.get('Sell Trade Info')\n",
    "            p_createdAt = parse_date(row.get('Created At'))\n",
    "\n",
    "            if bank_info and sell_amount_fx is not None and isinstance(p_createdAt, datetime):\n",
    "                parts = bank_info.lower().split('-')\n",
    "                if len(parts) >= 2:\n",
    "                    key_bank = normalize_bank_key(parts[0].strip())                                           \n",
    "                    key_currency = parts[1].strip().upper()\n",
    "                    # Similar to buy side, use the matched bank statement amount for the set\n",
    "                    matched_entry = next((item for item in matched_sell if item['Date'] == p_createdAt.strftime('%Y-%m-%d') and item['Trade Amount'] == sell_amount_fx), None)\n",
    "                    if matched_entry:\n",
    "\n",
    "                        matched_set.add((f\"{key_bank.replace(\"_bank\", \"\")} {key_currency}\", matched_entry['Bank Statement Amount'], matched_entry['Date']))\n",
    "\n",
    "\n",
    "    # Scan for unmatched bank records (records present in bank statements but not in FX trades)\n",
    "unmatched_bank_records = []\n",
    "\n",
    "for bank_key, bank_df in bank_dfs.items():\n",
    "    print(f\"Scanning bank table: {bank_key} for unmatched records...\")\n",
    "    bank_df.columns = bank_df.columns.str.strip()  # Clean column names\n",
    "    date_col = resolve_date_column(bank_df.columns.tolist())\n",
    "    amount_cols = get_amount_columns(bank_df.columns.tolist())\n",
    "    description_col = get_description_columns(bank_df.columns.tolist())\n",
    "    parts = bank_key.lower().split('_')\n",
    "    print(parts)\n",
    "    key_bank = f\"{normalize_bank_key(parts[0].strip())}\"\n",
    "    key_currency = parts[1].strip().upper()\n",
    "\n",
    "    print(\"Amount columns:\", amount_cols)\n",
    "\n",
    "    if not date_col or not amount_cols or not description_col:\n",
    "        print(f\"Skipping {bank_key}: Missing essential columns (Date, Amount, or Description).\")\n",
    "        continue\n",
    "\n",
    "    # Ensure date column is parsed to datetime\n",
    "    bank_df['_ParsedDate'] = bank_df[date_col].apply(parse_date)\n",
    "\n",
    "    for idx, row in bank_df.iterrows():\n",
    "        row_date_parsed = row.get('_ParsedDate')\n",
    "        if not isinstance(row_date_parsed, datetime):\n",
    "            continue  # Skip invalid date\n",
    "\n",
    "        description = str(row.get(description_col, '')).strip()\n",
    "\n",
    "        for amt_col in amount_cols:\n",
    "            amt_val = safe_float(row.get(amt_col))\n",
    "            if amt_val is None or abs(amt_val) < 0.01:\n",
    "                continue  # Skip zero or missing amounts\n",
    "\n",
    "            # Round amount to 2 decimal places for matching\n",
    "            rounded_amt = round(amt_val, 2)\n",
    "            \n",
    "            # Build the lookup key in the same format as in matched_set\n",
    "            # Build the lookup key in the same format as in matched_set\n",
    "            match_key = (f\"{key_bank} {key_currency}\", rounded_amt, row_date_parsed.strftime('%Y-%d-%m'))\n",
    "\n",
    "            print(\"\\n🔍 Checking match_key:\", match_key)\n",
    "            print(\"📘 Matched Set:\")\n",
    "            for item in matched_set:\n",
    "                print(\" \", item)\n",
    "\n",
    "            # Check for a match\n",
    "            if match_key in matched_set:\n",
    "                print(\"✅ Found match:\", match_key)\n",
    "            else:\n",
    "                print(\"❌ No match found. Adding to unmatched_bank_records.\")\n",
    "                unmatched_bank_records.append({\n",
    "                    'Bank Table': bank_key,\n",
    "                    'Date': row_date_parsed.strftime('%Y-%m-%d'),\n",
    "                    'Description': description,\n",
    "                    'Transaction Type (Column)': amt_col,\n",
    "                    'Amount': rounded_amt\n",
    "                })\n",
    "\n",
    "\n",
    "            # Optional: break if only one amount per row should be matched\n",
    "            # break\n",
    "\n",
    "else:\n",
    "    print(\"Please upload both FX Trade Tracker and Bank Statement CSV files before running this section.\")\n",
    "\n",
    "# Convert lists to DataFrames for easier analysis\n",
    "unmatched_buy_df = pd.DataFrame(unmatched_buy)\n",
    "unmatched_sell_df = pd.DataFrame(unmatched_sell)\n",
    "matched_buy_df = pd.DataFrame(matched_buy)\n",
    "matched_sell_df = pd.DataFrame(matched_sell)\n",
    "unmatched_bank_df = pd.DataFrame(unmatched_bank_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42e18a",
   "metadata": {},
   "source": [
    "## 6. Export Results\n",
    "This section exports the matched and unmatched records to CSV files for further review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unmatched FX (Buy Side)\n",
    "if not unmatched_buy_df.empty:\n",
    "    unmatched_buy_df.to_csv(out_csv_path_buy_unmatched, index=False)\n",
    "    print(f\"Exported unmatched Buy side FX records to: {out_csv_path_buy_unmatched}\")\n",
    "else:\n",
    "    print(\"No unmatched Buy side FX records to export.\")\n",
    "\n",
    "# Export unmatched FX (Sell Side)\n",
    "if not unmatched_sell_df.empty:\n",
    "    unmatched_sell_df.to_csv(out_csv_path_sell_unmatched, index=False)\n",
    "    print(f\"Exported unmatched Sell side FX records to: {out_csv_path_sell_unmatched}\")\n",
    "else:\n",
    "    print(\"No unmatched Sell side FX records to export.\")\n",
    "\n",
    "# Export matched FX (Buy Side)\n",
    "if not matched_buy_df.empty:\n",
    "    matched_buy_df.to_csv(out_csv_path_buy_matched, index=False)\n",
    "    print(f\"Exported matched Buy side FX records to: {out_csv_path_buy_matched}\")\n",
    "else:\n",
    "    print(\"No matched Buy side FX records to export.\")\n",
    "\n",
    "# Export matched FX (Sell Side)\n",
    "if not matched_sell_df.empty:\n",
    "    matched_sell_df.to_csv(out_csv_path_sell_matched, index=False)\n",
    "    print(f\"Exported matched Sell side FX records to: {out_csv_path_sell_matched}\")\n",
    "else:\n",
    "    print(\"No matched Sell side FX records to export.\")\n",
    "\n",
    "# Export bank-only unmatched records\n",
    "if not unmatched_bank_df.empty:\n",
    "    unmatched_bank_df.to_csv(out_csv_path_bank_unmatched, index=False)\n",
    "    print(f\"Exported unmatched bank records to: {out_csv_path_bank_unmatched}\")\n",
    "else:\n",
    "    print(\"No unmatched bank records to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab8462",
   "metadata": {},
   "source": [
    "## 7. Data Science Analysis and Visualizations\n",
    "This section provides a deeper dive into the reconciliation results using `pandas` for analysis and `seaborn` for visually appealing graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== DATA ANALYSIS AND VISUALIZATIONS =====\")\n",
    "\n",
    "# Ensure dataframes exist before attempting analysis\n",
    "if fx_trade_df.empty and (matched_buy_df.empty and unmatched_buy_df.empty) and \\\n",
    "   (matched_sell_df.empty and unmatched_sell_df.empty) and unmatched_bank_df.empty:\n",
    "    print(\"No data available for analysis. Please ensure files are loaded and reconciliation is complete.\")\n",
    "else:\n",
    "    # --- 7.1. Reconciliation Summary Statistics ---\n",
    "    print(\"\\n--- 7.1. Reconciliation Summary Statistics ---\")\n",
    "    total_fx_trades = len(fx_trade_df) if not fx_trade_df.empty else 0\n",
    "    total_buy_side_trades = len(fx_trade_df[fx_trade_df['Action Type'] == 'Bank Buy']) if not fx_trade_df.empty else 0\n",
    "    total_sell_side_trades = len(fx_trade_df[fx_trade_df['Action Type'] == 'Bank Sell']) if not fx_trade_df.empty else 0\n",
    "\n",
    "    print(f\"Total FX Trade Records (excluding cancelled/pending): {total_fx_trades - len(fx_trade_df[fx_trade_df['Status'].isin(['cancelled', 'pending'])]) if not fx_trade_df.empty else 0}\")\n",
    "    print(f\"Total Buy Side FX Trades processed: {total_buy_side_trades}\")\n",
    "    print(f\"Total Sell Side FX Trades processed: {total_sell_side_trades}\")\n",
    "    print(f\"Buy Side Matched: {len(matched_buy_df)} ({(len(matched_buy_df)/total_buy_side_trades*100):.2f}%)\" if total_buy_side_trades > 0 else \"Buy Side Matched: 0 (N/A%)\")\n",
    "    print(f\"Buy Side Unmatched: {len(unmatched_buy_df)} ({(len(unmatched_buy_df)/total_buy_side_trades*100):.2f}%)\" if total_buy_side_trades > 0 else \"Buy Side Unmatched: 0 (N/A%)\")\n",
    "    print(f\"Sell Side Matched: {len(matched_sell_df)} ({(len(matched_sell_df)/total_sell_side_trades*100):.2f}%)\" if total_sell_side_trades > 0 else \"Sell Side Matched: 0 (N/A%)\")\n",
    "    print(f\"Sell Side Unmatched: {len(unmatched_sell_df)} ({(len(unmatched_sell_df)/total_sell_side_trades*100):.2f}%)\" if total_sell_side_trades > 0 else \"Sell Side Unmatched: 0 (N/A%)\")\n",
    "    print(f\"Unmatched Bank Records (not found in FX trades): {len(unmatched_bank_df)}\")\n",
    "\n",
    "\n",
    "    # --- 7.2. Visualizing Reconciliation Status (Buy Side) ---\n",
    "    if not matched_buy_df.empty or not unmatched_buy_df.empty:\n",
    "        buy_status_counts = pd.DataFrame({\n",
    "            'Status': ['Matched Buy', 'Unmatched Buy'],\n",
    "            'Count': [len(matched_buy_df), len(unmatched_buy_df)]\n",
    "        })\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x='Status', y='Count', data=buy_status_counts)\n",
    "        plt.title('FX Buy Side Reconciliation Status')\n",
    "        plt.ylabel('Number of Trades')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo Buy Side data for reconciliation status visualization.\")\n",
    "\n",
    "    # --- 7.3. Visualizing Reconciliation Status (Sell Side) ---\n",
    "    if not matched_sell_df.empty or not unmatched_sell_df.empty:\n",
    "        sell_status_counts = pd.DataFrame({\n",
    "            'Status': ['Matched Sell', 'Unmatched Sell'],\n",
    "            'Count': [len(matched_sell_df), len(unmatched_sell_df)]\n",
    "        })\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x='Status', y='Count', data=sell_status_counts)\n",
    "        plt.title('FX Sell Side Reconciliation Status')\n",
    "        plt.ylabel('Number of Trades')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo Sell Side data for reconciliation status visualization.\")\n",
    "\n",
    "    # --- 7.4. Distribution of FX Trade Amounts ---\n",
    "    if not fx_trade_df.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1) # 1 row, 2 columns, first plot\n",
    "        sns.histplot(fx_trade_df['Buy Currency Amount'].dropna(), kde=True, bins=10)\n",
    "        plt.title('Distribution of Buy Currency Amounts (FX Trades)')\n",
    "        plt.xlabel('Amount')\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    "        plt.subplot(1, 2, 2) # 1 row, 2 columns, second plot\n",
    "        sns.histplot(fx_trade_df['Sell Currency Amount'].dropna(), kde=True, bins=10, color='orange')\n",
    "        plt.title('Distribution of Sell Currency Amounts (FX Trades)')\n",
    "        plt.xlabel('Amount')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo FX Trade data for amount distribution visualization.\")\n",
    "\n",
    "    # --- 7.5. Top Unmatched Bank Records by Amount ---\n",
    "    if not unmatched_bank_df.empty:\n",
    "        top_unmatched_bank = unmatched_bank_df.sort_values(by='Amount', ascending=False).head(10)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.barplot(x='Amount', y='Bank Table', hue='Transaction Type (Column)', data=top_unmatched_bank, dodge=True)\n",
    "        plt.title('Top 10 Unmatched Bank Records by Amount')\n",
    "        plt.xlabel('Amount')\n",
    "        plt.ylabel('Bank Account')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo unmatched bank records for top amount visualization.\")\n",
    "\n",
    "    # --- 7.6. Transaction Volume by Bank (Unmatched Bank Records) ---\n",
    "    if not unmatched_bank_df.empty:\n",
    "        bank_volume = unmatched_bank_df['Bank Table'].value_counts().reset_index()\n",
    "        bank_volume.columns = ['Bank Table', 'Count']\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='Count', y='Bank Table', data=bank_volume, palette='cubehelix')\n",
    "        plt.title('Number of Unmatched Transactions per Bank Account')\n",
    "        plt.xlabel('Number of Unmatched Transactions')\n",
    "        plt.ylabel('Bank Account')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNo unmatched bank records for transaction volume visualization.\")\n",
    "\n",
    "    # --- 7.7. Daily Transaction Trend (FX Trades) ---\n",
    "    if not fx_trade_df.empty and 'Created At' in fx_trade_df.columns:\n",
    "        # Filter out rows where 'Created At' could not be parsed\n",
    "        fx_trades_valid_dates = fx_trade_df.dropna(subset=['Created At']).copy()\n",
    "        fx_trades_valid_dates['DateOnly'] = fx_trades_valid_dates['Created At']\n",
    "        daily_counts = fx_trades_valid_dates['DateOnly'].value_counts().sort_index().reset_index()\n",
    "        daily_counts.columns = ['Date', 'Count']\n",
    "\n",
    "        if len(daily_counts) > 1: # Only plot trend if there's more than one date\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.lineplot(x='Date', y='Count', data=daily_counts, marker='o')\n",
    "            plt.title('Daily FX Trade Transaction Count')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Number of Trades')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"\\nNot enough date diversity in FX trades for daily trend visualization.\")\n",
    "    else:\n",
    "        print(\"\\nNo FX Trade data with valid dates for daily trend visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12bae6",
   "metadata": {},
   "source": [
    "## 8. Overall Summary\n",
    "A final comprehensive summary of the reconciliation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bee88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== OVERALL RECONCILIATION SUMMARY =====\")\n",
    "print(f\"✅ BUY Side Matches (Counterparty Payment): {len(matched_buy_df)}\")\n",
    "print(f\"❌ BUY Side Unmatched: {len(unmatched_buy_df)}\")\n",
    "print(f\"✅ SELL Side Matches (Choice Payment): {len(matched_sell_df)}\")\n",
    "print(f\"❌ SELL Side Unmatched: {len(unmatched_sell_df)}\")\n",
    "print(f\"📤 Bank-only unmatched entries: {len(unmatched_bank_df)}\")\n",
    "print(\"\\nReconciliation process and data analysis complete. Review the generated CSVs and visualizations for insights.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
